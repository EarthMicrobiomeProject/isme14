{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**author**: lukethompson@gmail.com<br>\n",
    "**date**: 16 Nov 2016<br>\n",
    "**language**: Python 3.5<br>\n",
    "**conda environment**: emp-py3<br>\n",
    "**license**: unlicensed<br>\n",
    "\n",
    "## otu_trading_cards.ipynb\n",
    "\n",
    "Generate LaTeX macros and plots for a 'trading card' for any given Deblur OTU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biom\n",
    "import wikipedia\n",
    "import re\n",
    "import os\n",
    "import errno\n",
    "import math\n",
    "import html\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import empcolors\n",
    "import GetV4Region\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seaborn plot settings\n",
    "sns.set_context('talk')\n",
    "sns.set(style='white', palette='muted', color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "path_map = 'input-tsv/emp_qiime_mapping_subset_2k.tsv'\n",
    "path_otus = 'input-tsv/otu_summary.emp_deblur_100bp.subset_2k.rare_5000.tsv'\n",
    "path_rdp = 'input-tsv/otu_seqs_top_500_prev.emp_deblur_100bp.subset_2k.rare_5000.tsv'\n",
    "obs_column = 'observations_deblur_100bp'\n",
    "trim_length = 100\n",
    "num_samples = 1856 # 2000 for 90bp, 1856 for 100bp, 975 for 150bp\n",
    "rarefaction_depth = 5000\n",
    "subset = '2k'\n",
    "\n",
    "# output\n",
    "path_output = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe of colors\n",
    "df_colors = pd.DataFrame.from_dict(empcolors.get_empo_cat_color(returndict=True), orient='index')\n",
    "df_colors.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get wikipedia entry for genus or higher (lowest taxonomic level that begins (position 3) with capital letter)\n",
    "def get_wikipedia(my_taxonomy):\n",
    "    for level in reversed(my_taxonomy.split('; ')):\n",
    "        if len(level) > 3:\n",
    "            if level[3].isupper():\n",
    "                title = level[3:]\n",
    "                print(title)\n",
    "                try:\n",
    "                    entry = wikipedia.page(title)\n",
    "                    return('%s\\t%s' % (title, entry.summary))\n",
    "                except wikipedia.exceptions.DisambiguationError as e:\n",
    "                    return('%s\\t%s has multiple options: %s' % (title, title, e.options))\n",
    "                except wikipedia.exceptions.PageError as e:\n",
    "                    return('%s\\t%s has no Wikipedia page.' % (title, title))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make directory if doesn't already exist\n",
    "def make_directory(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise exc\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read mapping file\n",
    "df_map = pd.read_csv(path_map, sep='\\t', index_col=0)\n",
    "# read otu summary\n",
    "df_otus = pd.read_csv(path_otus, sep='\\t', index_col=0)\n",
    "# read rdp taxonomy (index = sequence)\n",
    "df_rdp = pd.read_csv(path_rdp, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Get OTUs matching to query 16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path in ['RefSeq_16S/Bacteroides_coprocola_M16.NR_041278.fasta',\n",
    "             'RefSeq_16S/Bacteroides_dorei_175.NR_041351.fasta',\n",
    "             'RefSeq_16S/Bacteroides_intestinalis_341.NR_041307.fasta']:\n",
    "    GetV4Region.GetV4(inputname=path, \n",
    "                  fprimer='GTGCCAGC[AC]GCCGCGGTAA',\n",
    "                  rprimer='ATTAGA[AT]ACCC[CGT][AGT]GTAGTCC',\n",
    "                  length=100,\n",
    "                  remove_ambig=False,\n",
    "                  keep_primers=False,\n",
    "                  skip_reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bacteroides = [\n",
    "        'TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGCAGACGGGAGATTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "        'TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "        'TACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGGCGGATTATTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTG',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(bacteroides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_otus_top = df_otus[df_otus['sequence'].isin(bacteroides)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO: Add fasta name to df_otus_top so we can track the strains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Get top OTUs by num_samples OR total_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_otus_top = df_otus.sort_values('num_samples', ascending=False).head(10)\n",
    "df_otus_top = df_otus.sort_values('total_obs', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_otus_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add wikipedia summary\n",
    "df_otus_top['wikipedia'] = df_otus_top['taxonomy'].apply(get_wikipedia)\n",
    "df_otus_top['title'] = [value.split('\\t')[0] for value in df_otus_top['wikipedia']]\n",
    "df_otus_top['wikipedia'] = [value.split('\\t')[1] for value in df_otus_top['wikipedia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_svg(svg_fp, id):\n",
    "    svg_code = []\n",
    "    with open(svg_fp, 'r') as source:\n",
    "        reading = False\n",
    "        for line in source:\n",
    "            if line.startswith('<svg'):\n",
    "                line = '<svg id=\"%s\"%s' % (id, line[4:])\n",
    "                reading = True\n",
    "            if reading == True:\n",
    "                svg_code.append(line.rstrip())\n",
    "    return '\\n'.join(svg_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, row in df_otus_top.iterrows():\n",
    "    \n",
    "    # store the relevant values\n",
    "    sequence = row['sequence']\n",
    "    taxonomy_gg = re.sub(r'_', r'\\_', row['taxonomy'])\n",
    "    try:\n",
    "        df_rdp.loc[row['sequence']]\n",
    "        taxonomy_rdp = re.sub(r'_', r'\\_', df_rdp.loc[row['sequence']]['lineage_count'])\n",
    "        species_1st_rdp = df_rdp.loc[row['sequence']]['species_1st_count']\n",
    "        species_2nd_rdp = df_rdp.loc[row['sequence']]['species_2nd_count']\n",
    "        species_3rd_rdp = df_rdp.loc[row['sequence']]['species_3rd_count']\n",
    "    except:\n",
    "        taxonomy_rdp = ''\n",
    "        species_1st_rdp = ''\n",
    "        species_2nd_rdp = ''\n",
    "        species_3rd_rdp = ''\n",
    "    wikipedia = row['wikipedia']\n",
    "    wikipedia = re.sub(r'\"', r'``', wikipedia)\n",
    "    wikipedia = re.sub(u'\\u201D', r\"''\", wikipedia) # need to replace unicode backward double quote\n",
    "    title = row['title']\n",
    "    prevalencePercent = row['num_samples_frac'] * 100\n",
    "    prevalenceRank = str(row['num_samples_rank'] + 1)\n",
    "    abundancePercent = row['total_obs_frac'] * 100\n",
    "    abundanceRank = str(row['total_obs_rank'] + 1)\n",
    "    numOTUs = str(df_otus.shape[0])\n",
    "    trimLength = str(trim_length)\n",
    "    numSamples = str(num_samples)\n",
    "    rarefactionDepth = str(rarefaction_depth)\n",
    "\n",
    "    # MAKE DIRECTORY\n",
    "    target_dir = '%s/card_%sbp_subset%s_rare%s_rank%s_%s' % (path_output, \n",
    "            trimLength, subset, rarefactionDepth, prevalenceRank, title)\n",
    "    make_directory(target_dir)\n",
    "    \n",
    "    # CREATE WEB PAGE\n",
    "    with open('template.html', 'r') as source:\n",
    "        template_html = source.read()\n",
    "    with open('template.js', 'r') as source:\n",
    "        template_js = source.read()\n",
    "    with open('template.css', 'r') as source:\n",
    "        template_css = source.read()\n",
    "    with open('%s/otu_trading_card.html' % target_dir, 'w') as target:\n",
    "        target.write('<!DOCTYPE html>\\n')\n",
    "        target.write('<html>\\n')\n",
    "        target.write('<head>\\n')\n",
    "        target.write('  <title>%s</title>\\n' % title)\n",
    "        # STYLE SHEET\n",
    "        target.write('  <style type=\"text/css\">\\n')\n",
    "        for line in template_css.split('\\n'):\n",
    "            target.write('    %s\\n' % line)\n",
    "        target.write('  </style>\\n')\n",
    "        # OTU PROPERTIES\n",
    "        target.write('  <script type=\"text/javascript\">\\n')\n",
    "        # SEQUENCE\n",
    "        target.write('    var sequence = \\'%s\\';\\n' % sequence)\n",
    "        # TAXONOMY\n",
    "        target.write('    var taxonomyGG = \\'%s\\';\\n' % taxonomy_gg)\n",
    "        target.write('    var taxonomyRDP = \\'%s\\';\\n' % taxonomy_rdp)\n",
    "        target.write('    var speciesA = \\'%s\\';\\n' % species_1st_rdp)\n",
    "        target.write('    var speciesB = \\'%s\\';\\n' % species_2nd_rdp)\n",
    "        target.write('    var speciesC = \\'%s\\';\\n' % species_3rd_rdp)\n",
    "        # WIKIPEDIA\n",
    "        target.write('    var wikipedia = \\'%s\\';\\n' % html.escape(wikipedia).replace('\\n', '<br>'))\n",
    "        # PREVALENCE\n",
    "        target.write('    var prevalencePercent = \\'%s\\';\\n' % '{:0.2f}'.format(prevalencePercent))\n",
    "        target.write('    var prevalenceRank = \\'%s\\';\\n' % prevalenceRank)\n",
    "        # ABUNDANCE\n",
    "        target.write('    var abundancePercent = \\'%s\\';\\n' % '{:0.3f}'.format(abundancePercent))\n",
    "        target.write('    var abundanceRank = \\'%s\\';\\n' % abundanceRank)\n",
    "        # METHODS/MISC\n",
    "        target.write('    var numOTUs = \\'%s\\';\\n' % numOTUs)\n",
    "        target.write('    var trimLength = \\'%s\\';\\n' % trimLength)\n",
    "        target.write('    var numSamples = \\'%s\\';\\n' % numSamples)\n",
    "        target.write('    var rarefactionDepth = \\'%s\\';\\n' % rarefactionDepth)\n",
    "        target.write('  </script>\\n')        \n",
    "        # SCRIPTS TO RENDER THE PAGE\n",
    "        target.write('  <script type=\"text/javascript\">\\n')\n",
    "        for line in template_js.split('\\n'):\n",
    "            target.write('    %s\\n' % line)\n",
    "        target.write('  </script>\\n')\n",
    "        target.write('</head>\\n')\n",
    "        # DISPLAY ELEMENTS\n",
    "        target.write('<body>\\n')\n",
    "        for line in template_html.split('\\n'):\n",
    "            target.write('  %s\\n' % line)\n",
    "\n",
    "    # CREATE MACROS FILE\n",
    "    with open('%s/card_%sbp_subset%s_rare%s_rank%s_%s/macros.tex' % (path_output, \n",
    "            trimLength, subset, rarefactionDepth, prevalenceRank, title), 'w') as target:\n",
    "        # SEQUENCE\n",
    "        target.write(r'\\def\\sequence{')\n",
    "        # first 50bp\n",
    "        target.write(sequence[:50])\n",
    "        # next 50bp\n",
    "        target.write('\\n')\n",
    "        target.write(sequence[50:100])\n",
    "        # next 50bp if > 100bp\n",
    "        if len(sequence) > 100:\n",
    "            target.write('\\n')\n",
    "            target.write(sequence[100:150])\n",
    "        target.write('}\\n')\n",
    "        # TAXONOMY\n",
    "        target.write(r'\\def\\taxonomyGG{')\n",
    "        target.write(taxonomy_gg)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\taxonomyRDP{')\n",
    "        target.write(taxonomy_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesA{')\n",
    "        target.write(species_1st_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesB{')\n",
    "        target.write(species_2nd_rdp)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\speciesC{')\n",
    "        target.write(species_3rd_rdp)\n",
    "        target.write('}\\n')\n",
    "        # WIKIPEDIA\n",
    "        target.write(r'\\def\\wikipedia{')\n",
    "        if len(wikipedia) > 650:\n",
    "            target.write(wikipedia[:650])\n",
    "            target.write('...')\n",
    "        else:\n",
    "            target.write(wikipedia)\n",
    "        target.write('}\\n')\n",
    "        # PREVALENCE\n",
    "        target.write(r'\\def\\prevalencePercent{')\n",
    "        target.write('{:0.2f}'.format(prevalencePercent))\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\prevalenceRank{')\n",
    "        target.write(prevalenceRank)\n",
    "        target.write('}\\n')\n",
    "        # ABUNDANCE\n",
    "        target.write(r'\\def\\abundancePercent{')\n",
    "        target.write('{:0.3f}'.format(abundancePercent))\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\abundanceRank{')\n",
    "        target.write(abundanceRank)\n",
    "        target.write('}\\n')\n",
    "        # METHODS/MISC\n",
    "        target.write(r'\\def\\numOTUs{')\n",
    "        target.write(numOTUs)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\trimLength{')\n",
    "        target.write(trimLength)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\numSamples{')\n",
    "        target.write(numSamples)\n",
    "        target.write('}\\n')\n",
    "        target.write(r'\\def\\rarefactionDepth{')\n",
    "        target.write(rarefactionDepth)\n",
    "        target.write('}\\n')\n",
    "        \n",
    "    # EMPO_3 PIE CHART OF PRESENCE/ABSENCE\n",
    "    # value counts of empo_3 categories of samples OTU is found in\n",
    "    empo3_count = df_map.loc[row['list_samples'].split(',')]['empo_3'].value_counts()\n",
    "    # concat colors with counts and then remove zero values\n",
    "    df_empo3 = pd.concat([df_colors, empo3_count], axis=1)\n",
    "    df_empo3.columns = ['color', 'count']\n",
    "    df_empo3_nonzero = df_empo3[df_empo3['count'] > 0]\n",
    "    # draw pie chart\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    fig.set_size_inches(5.6, 3)\n",
    "    patches, text = plt.pie(df_empo3_nonzero['count'], labels=df_empo3_nonzero.index, colors=df_empo3_nonzero['color'], startangle=0)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/pie.pdf' % target_dir)\n",
    "    plt.savefig('%s/pie.svg' % target_dir)\n",
    "    pie_svg = read_svg('%s/pie.svg' % target_dir, 'pie-svg')\n",
    "    os.remove('%s/pie.svg' % target_dir)\n",
    "    with open('%s/otu_trading_card.html' % target_dir, 'a') as target:\n",
    "        target.write('\\n%s\\n' % pie_svg)\n",
    "\n",
    "    # EMPO_3 POINT PLOT OF PRESENCE/ABSENCE\n",
    "    # value counts of empo3 counts in subset of samples\n",
    "    vc_empo3_subset = df_map[df_map['observations_deblur_100bp'] >= 5000]['empo_3'].value_counts()\n",
    "    df_empo3_nonzero.loc[:, 'count_all'] = vc_empo3_subset[df_empo3_nonzero.index] * 0.5\n",
    "    # normalize counts to total\n",
    "    df_empo3_nonzero['count_all_norm'] = df_empo3_nonzero['count_all'] / df_empo3_nonzero['count_all'].sum()\n",
    "    df_empo3_nonzero['count_norm'] = df_empo3_nonzero['count'] / df_empo3_nonzero['count'].sum()\n",
    "    # add empo column and reorder columns\n",
    "    df_empo3_nonzero['empo'] = df_empo3_nonzero.index\n",
    "    df_empo3_nonzero = df_empo3_nonzero[['empo', 'color', 'count_all', 'count', 'count_all_norm', 'count_norm']]\n",
    "    # melt to format that is plot-able\n",
    "    df_empo3_nonzero_melted = pd.melt(df_empo3_nonzero, id_vars=['empo', 'color'], value_vars=['count_norm', 'count_all_norm'])\n",
    "    df_empo3_nonzero_melted.sort_values('variable', ascending=True, inplace=True)\n",
    "    # point plot\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.pointplot(x='variable', y='value', hue='empo', data=df_empo3_nonzero_melted, palette=df_empo3_nonzero_melted['color'])\n",
    "    plt.legend().set_visible(False)\n",
    "    for empo in df_empo3_nonzero.index:\n",
    "        mysize = 8+40*df_empo3_nonzero.loc[empo,'count_norm']\n",
    "        if mysize > 16:\n",
    "            mysize = 16\n",
    "        plt.text(1.08, df_empo3_nonzero.loc[empo,'count_norm'], df_empo3_nonzero.loc[empo,'empo'], fontsize=mysize, va='center')\n",
    "    plt.axis([-0.1, 2.5, -0.01, df_empo3_nonzero['count_norm'].max()*1.1])\n",
    "    plt.box('off')\n",
    "    plt.xticks([0, 1], ('All samples', 'Samples where OTU is found'))\n",
    "    ax.tick_params(labelsize=10)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Relative distribution by EMPO sample type', fontsize=10)\n",
    "    sns.despine(offset=10, trim=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/point.pdf' % target_dir)\n",
    "    plt.savefig('%s/point.svg' % target_dir)\n",
    "    point_svg = read_svg('%s/point.svg' % target_dir, 'point-svg')\n",
    "    os.remove('%s/point.svg' % target_dir)\n",
    "    with open('%s/otu_trading_card.html' % target_dir, 'a') as target:\n",
    "        target.write('\\n%s\\n' % point_svg)\n",
    "    \n",
    "    # ENVIRONMENTAL PARAMETER DISTRIBUTION PLOTS OF PRESENCE/ABSENCE\n",
    "    # get ph values of samples OTU is found in\n",
    "    ph_values = df_map.loc[row['list_samples'].split(',')]['ph']\n",
    "    ph_values.dropna(inplace=True)\n",
    "    all_ph_values = df_map[df_map[obs_column] >= 5000]['ph']\n",
    "    all_ph_values.dropna(inplace=True)\n",
    "    # get temperature values of samples OTU is found in\n",
    "    temp_values = df_map.loc[row['list_samples'].split(',')]['temperature_deg_c']\n",
    "    temp_values.dropna(inplace=True)\n",
    "    all_temp_values = df_map[df_map[obs_column] >= 5000]['temperature_deg_c']\n",
    "    all_temp_values.dropna(inplace=True)\n",
    "    # get salinity values of samples OTU is found in\n",
    "    sal_values = df_map.loc[row['list_samples'].split(',')]['salinity_psu']\n",
    "    sal_values.dropna(inplace=True)\n",
    "    all_sal_values = df_map[df_map[obs_column] >= 5000]['salinity_psu']\n",
    "    all_sal_values.dropna(inplace=True)\n",
    "    # draw dist plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(7, 2))\n",
    "    sns.despine(left=True)\n",
    "    # ph\n",
    "    sns.distplot(all_ph_values, hist=False, rug=False, color='0.8', ax=axes[0], kde_kws={\"shade\": True})\n",
    "    if ph_values.shape[0] > 1:\n",
    "        sns.distplot(ph_values, hist=False, rug=True, color='g', ax=axes[0], axlabel='pH', kde_kws={\"shade\": True})\n",
    "    # temp\n",
    "    sns.distplot(all_temp_values, hist=False, rug=False, color='0.8', ax=axes[1], kde_kws={\"shade\": True})\n",
    "    if temp_values.shape[0] > 1:\n",
    "        sns.distplot(temp_values, hist=False, rug=True, color='r', ax=axes[1], axlabel='Temperature (°C)', kde_kws={\"shade\": True})\n",
    "    # sal\n",
    "    sns.distplot(all_sal_values, hist=False, rug=False, color='0.8', ax=axes[2], kde_kws={\"shade\": True})\n",
    "    if sal_values.shape[0] > 1:\n",
    "        sns.distplot(sal_values, hist=False, rug=True, color='b', ax=axes[2], axlabel='Salinity (psu)', kde_kws={\"shade\": True})\n",
    "    axes[0].set_xlim([math.floor(all_ph_values.min()), math.ceil(all_ph_values.max())])\n",
    "    axes[1].set_xlim([math.floor(all_temp_values.min()), math.ceil(all_temp_values.max())])\n",
    "    axes[2].set_xlim([math.floor(all_sal_values.min()), math.ceil(all_sal_values.max())])\n",
    "    plt.setp(axes, yticks=[])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('%s/envparams.pdf' % target_dir)\n",
    "    plt.savefig('%s/envparams.svg' % target_dir)\n",
    "    envparams_svg = read_svg('%s/envparams.svg' % target_dir, 'envparams-svg')\n",
    "    os.remove('%s/envparams.svg' % target_dir)\n",
    "    with open('%s/otu_trading_card.html' % target_dir, 'a') as target:\n",
    "        target.write('\\n%s\\n' % envparams_svg)\n",
    "\n",
    "    # FINISH WRITING WEB PAGE\n",
    "    with open('%s/otu_trading_card.html' % target_dir, 'a') as target:\n",
    "        target.write('<p style=\"text-align: center\">&#169; 2016 Earth Microbiome Project</p>\\n')\n",
    "        target.write('</body>\\n')\n",
    "        target.write('</html>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:emp-py3]",
   "language": "python",
   "name": "conda-env-emp-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
